<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="color-scheme" content="light dark">

    

    
    <meta name="description" content="What is Variational Inference? Variational Inference is a technique used in Bayesian Statistics to approximate $p ( z \mid x)$ the conditional density of an unknown variable, z given an observed variable, x through optimization. To find this approximate density:
select a family of densities, $\mathscr{D}$ over the latent variables. Each member of the family q(z) $\in \mathscr{D}$ is a candidate approximation to the true density. The optimization problem is then to find the member of this family which is closest in Kullback-Leibler (KL) divergence to the conditional density of interest: $$ q^{*} (z) = \underset{q(z) \in \mathscr{D}}{\text{arg min}} \quad \text{KL} (q(z) \mid \mid p(z \mid x)) $$ Kullback-Leibler Divergence The divergence between two probability distributions is a statistical distance or scoring of how the distributions differ from each other.">
    <meta name="keywords" content="">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Variational Inference"/>
<meta name="twitter:description" content="What is Variational Inference? Variational Inference is a technique used in Bayesian Statistics to approximate $p ( z \mid x)$ the conditional density of an unknown variable, z given an observed variable, x through optimization. To find this approximate density:
select a family of densities, $\mathscr{D}$ over the latent variables. Each member of the family q(z) $\in \mathscr{D}$ is a candidate approximation to the true density. The optimization problem is then to find the member of this family which is closest in Kullback-Leibler (KL) divergence to the conditional density of interest: $$ q^{*} (z) = \underset{q(z) \in \mathscr{D}}{\text{arg min}} \quad \text{KL} (q(z) \mid \mid p(z \mid x)) $$ Kullback-Leibler Divergence The divergence between two probability distributions is a statistical distance or scoring of how the distributions differ from each other."/>

    <meta property="og:title" content="Variational Inference" />
<meta property="og:description" content="What is Variational Inference? Variational Inference is a technique used in Bayesian Statistics to approximate $p ( z \mid x)$ the conditional density of an unknown variable, z given an observed variable, x through optimization. To find this approximate density:
select a family of densities, $\mathscr{D}$ over the latent variables. Each member of the family q(z) $\in \mathscr{D}$ is a candidate approximation to the true density. The optimization problem is then to find the member of this family which is closest in Kullback-Leibler (KL) divergence to the conditional density of interest: $$ q^{*} (z) = \underset{q(z) \in \mathscr{D}}{\text{arg min}} \quad \text{KL} (q(z) \mid \mid p(z \mid x)) $$ Kullback-Leibler Divergence The divergence between two probability distributions is a statistical distance or scoring of how the distributions differ from each other." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adityaanand7.github.io/posts/vi/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-05-05T00:00:00+00:00" />



    <title>
  Variational Inference · home
</title>

    
      <link rel="canonical" href="https://adityaanand7.github.io/posts/vi/">
    

    <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>

    
      
      
      <link rel="stylesheet" href="/css/coder.min.d9fddbffe6f27e69985dc5fe0471cdb0e57fbf4775714bc3d847accb08f4a1f6.css" integrity="sha256-2f3b/&#43;byfmmYXcX&#43;BHHNsOV/v0d1cUvD2Eesywj0ofY=" crossorigin="anonymous" media="screen" />
    

    

    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

    <meta name="generator" content="Hugo 0.102.3" />
  </head>

  
  
  <body class="preload-transitions colorscheme-light">
    
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      home
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/publications">Publications</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/teaching">Teaching</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/posts">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/cv.pdf">CV</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="https://adityaanand7.github.io/posts/vi/">
              Variational Inference
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2022-05-05T00:00:00Z">
                May 5, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fa fa-clock-o" aria-hidden="true"></i>
              One-minute read
            </span>
          </div>
          
          
          
        </div>
      </header>

      <div>
        
        <h1 align="center">What is Variational Inference? </h1>
<p><strong>Variational Inference</strong> is a technique used in Bayesian Statistics to approximate <strong>$p ( z \mid x)$</strong> the conditional density of an unknown variable, <strong>z</strong> given an observed variable, <strong>x</strong> through optimization. To find this approximate density:</p>
<ul>
<li>select a family of densities, $\mathscr{D}$ over the latent variables. Each member of the family q(z) $\in \mathscr{D}$ is a candidate approximation to the true density.</li>
<li>The optimization problem is then to find the member of this family which is closest in <strong>Kullback-Leibler (KL) divergence</strong> to the conditional density of interest:
$$
q^{*} (z) = \underset{q(z) \in \mathscr{D}}{\text{arg min}} \quad \text{KL} (q(z) \mid \mid p(z \mid x))
$$</li>
</ul>
<h4 id="kullback-leibler-divergence">
  Kullback-Leibler Divergence
  <a class="heading-link" href="#kullback-leibler-divergence">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<p>The <strong>divergence</strong> between two probability distributions is a statistical distance or scoring of how the distributions differ from each other. The <strong>Kullback-Leibler Divergence</strong>: D$_{KL} (P \mid \mid Q)$ <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> is also known as <strong>relative entropy</strong> and intuitively it is considered as the expected <strong>surprise</strong> from using Q as a model when the true distribution is P..</p>
<h4 id="elbo">
  ELBO
  <a class="heading-link" href="#elbo">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<p>The <strong>Evidence Lower Bound</strong></p>
<h4 id="citations">
  Citations
  <a class="heading-link" href="#citations">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h4>
<p><cite> <a href="https://arxiv.org/pdf/1601.00670.pdf">Variational Inference: A Review for Statisticians</a></p>
<div class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn:1">
<p>$\mid \mid$ indicates divergence&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mlbytes" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        
        
      </footer>
    </article>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
    integrity="sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
    integrity="sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body,
      {
        delimiters: [
          {left: '$$', right: '$$', display:true},
          {left: '$', right: '$', display:false},
          {left: '\\(', right: '\\)', display: false},
          {left: '\\[', right: '\\]', display: true}
        ]
      }
    );"></script>
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    ©
    
    2023
    
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

    </main>

    
      
      <script src="/js/coder.min.9cf2dbf9b6989ef8eae941ffb4231c26d1dc026bca38f1d19fdba50177d8a9ac.js" integrity="sha256-nPLb&#43;baYnvjq6UH/tCMcJtHcAmvKOPHRn9ulAXfYqaw="></script>
    

    

    

    

    

    

    

    

    
  </body>

</html>
